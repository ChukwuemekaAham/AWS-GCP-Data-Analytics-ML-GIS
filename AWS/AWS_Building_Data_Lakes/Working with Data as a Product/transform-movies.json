{
	"jobConfig": {
		"name": "transform-movies",
		"description": "",
		"role": "arn:aws:iam::022318916157:role/AdminGlueServiceRole",
		"command": "glueetl",
		"version": "2.0",
		"runtime": null,
		"workerType": "G.1X",
		"numberOfWorkers": 10,
		"maxCapacity": 10,
		"maxRetries": 0,
		"timeout": 2880,
		"maxConcurrentRuns": 1,
		"security": "none",
		"scriptName": "GlueJob.py",
		"scriptLocation": "s3://databucket-us-west-2-1453430398056634/jobs/",
		"language": "python-3",
		"jobParameters": [],
		"tags": [],
		"jobMode": "DEVELOPER_MODE",
		"createdOn": "2023-07-15T18:52:17.155Z",
		"developerMode": false,
		"connectionsList": [],
		"etlAutoTuning": true,
		"flexExecution": false,
		"minFlexWorkers": null
	},
	"hasBeenSaved": false,
	"script": "import sys\nfrom awsglue.transforms import *\nfrom awsglue.utils import getResolvedOptions\nfrom pyspark.context import SparkContext\nfrom awsglue.context import GlueContext\nfrom awsglue.job import Job\nfrom awsglue.dynamicframe import DynamicFrameCollection\nfrom awsglue.dynamicframe import DynamicFrame\nfrom awsglueml.transforms import FillMissingValues\n\n# Script: Finds any distinct rows from the .csv file that do not yet exist in the AWS Glue Data Catalog to append to the AWS Glue Data Catalog movies table in the transform-movies-db database\ndef MyTransform(glueContext, dfc) -> DynamicFrameCollection:\n    # new dataframe from collection\n    new_dynf = dfc.select(list(dfc.keys())[1])\n    # old dataframe from the AWS Glue Data Catalog\n    old_dynf = dfc.select(list(dfc.keys())[0])\n\n    # convert dynamicframe to dataframe\n    new_df = new_dynf.toDF()\n    old_df = old_dynf.toDF()\n\n    # print rows of new and old dataframes\n    print(\"new dataframe\")\n    new_df.show(n=5, vertical=True, truncate=50)\n    print(\"old dataframe\")\n    old_df.show(n=5, vertical=True, truncate=50)\n\n    # find any destinct rows from the .csv file that do not yet exist in the AWS Glue Data Catalog\n    if old_df.count() == 0:\n        # if this is the first time the job runs, append the full set of new data\n        update_df = new_df\n    else:\n        # else, if there is already data in the AWS Glue Data Catalog, find all of the data from the .csv file that is not already in the AWS Glue Data Catalog\n        # the left_anti join removes all duplicate records\n        # this data will be appended later in Node 8\n        update_df = new_df.join(old_df, [new_df.rank == old_df.rank], how=\"left_anti\")\n\n    # print unique rows from new data\n    print(\"unique rows\")\n    update_df.show(n=5, vertical=True, truncate=50)\n\n    # convert changed dataframe to dynamic dataframe\n    update_dynf = DynamicFrame.fromDF(update_df, glueContext, \"changed\")\n\n    # return new dynamicframe collection with only the new results\n    return DynamicFrameCollection({\"update_dynf\": update_dynf}, glueContext)\n\n\nargs = getResolvedOptions(sys.argv, [\"JOB_NAME\"])\nsc = SparkContext()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\njob = Job(glueContext)\njob.init(args[\"JOB_NAME\"], args)\n\n# Node 1: Input data from the data/movies_csv/movies.csv file in the S3 bucket\nS3_bucket_node_1 = glueContext.create_dynamic_frame.from_options(\n    format_options={\n        \"quoteChar\": '\"',\n        \"withHeader\": True,\n        \"separator\": \",\",\n        \"optimizePerformance\": False,\n    },\n    connection_type=\"s3\",\n    format=\"csv\",\n    connection_options={\n        \"paths\": [\n            \"s3://databucket-us-west-2-1453430398056634/data/movies_csv/movies.csv\"\n        ],\n        \"recurse\": True,\n    },\n    transformation_ctx=\"S3_bucket_node_1\",\n)\n\n# Node 2: Input data from the AWS Glue Data Catalog movies table in the transform-movies-db database\nAmazon_S3_node_2 = glueContext.create_dynamic_frame.from_catalog(\n    database=\"transform-movies-db\",\n    table_name=\"movies\",\n    transformation_ctx=\"Amazon_S3_node_2\",\n)\n\n# Node 3: Fill missing values in the data from the .csv file\nFill_Missing_Values_node_3 = FillMissingValues.apply(\n    frame=S3_bucket_node_1,\n    missing_values_column=\"rating\",\n    transformation_ctx=\"Fill_Missing_Values_node_3\",\n)\n\n# Node 4: Apply mapping to the data stored in the AWS Glue Data Catalog movies table in the transform-movies-db database\nChange_Schema_Apply_Mapping_node_4 = ApplyMapping.apply(\n    frame=Amazon_S3_node_2,\n    mappings=[\n        (\"year\", \"long\", \"year\", \"bigint\"),\n        (\"title\", \"string\", \"title\", \"string\"),\n        (\"directors_0\", \"string\", \"directors_0\", \"string\"),\n        (\"genres_0\", \"string\", \"genres_0\", \"string\"),\n        (\"genres_1\", \"string\", \"genres_1\", \"string\"),\n        (\"rank\", \"long\", \"rank\", \"bigint\"),\n        (\"running_time_secs\", \"long\", \"running_time_secs\", \"bigint\"),\n        (\"actors_0\", \"string\", \"actors_0\", \"string\"),\n        (\"actors_1\", \"string\", \"actors_1\", \"string\"),\n        (\"actors_2\", \"string\", \"actors_2\", \"string\"),\n        (\"directors_1\", \"string\", \"directors_1\", \"string\"),\n        (\"directors_2\", \"string\", \"directors_2\", \"string\"),\n        (\"rating_filled\", \"double\", \"rating_filled\", \"double\"),\n    ],\n    transformation_ctx=\"Change_Schema_Apply_Mapping_node_4\",\n)\n\n# Node 5: Apply mapping to the data from the .csv file\nChange_Schema_Apply_Mapping_node_5 = ApplyMapping.apply(\n    frame=Fill_Missing_Values_node_3,\n    mappings=[\n        (\"year\", \"string\", \"year\", \"bigint\"),\n        (\"title\", \"string\", \"title\", \"string\"),\n        (\"directors_0\", \"string\", \"directors_0\", \"string\"),\n        (\"genres_0\", \"string\", \"genres_0\", \"string\"),\n        (\"genres_1\", \"string\", \"genres_1\", \"string\"),\n        (\"rank\", \"string\", \"rank\", \"bigint\"),\n        (\"running_time_secs\", \"string\", \"running_time_secs\", \"bigint\"),\n        (\"actors_0\", \"string\", \"actors_0\", \"string\"),\n        (\"actors_1\", \"string\", \"actors_1\", \"string\"),\n        (\"actors_2\", \"string\", \"actors_2\", \"string\"),\n        (\"directors_1\", \"string\", \"directors_1\", \"string\"),\n        (\"directors_2\", \"string\", \"directors_2\", \"string\"),\n        (\"rating_filled\", \"string\", \"rating_filled\", \"double\"),\n    ],\n    transformation_ctx=\"Change_Schema_Apply_Mapping_node_5\",\n)\n\n# Node 6: Use the MyTransform script to find any distinct records from the new dataframe that are not already in the AWS Glue Data Catalog movies table in the transform-movies-db database. Then, return those records to be appended in Node 8.\nCustomTransform_node_6 = MyTransform(\n    glueContext,\n    DynamicFrameCollection(\n        {\n            \"Change_Schema_Apply_Mapping_node_4\": Change_Schema_Apply_Mapping_node_4,\n            \"Change_Schema_Apply_Mapping_node_5\": Change_Schema_Apply_Mapping_node_5,\n        },\n        glueContext,\n    ),\n)\n\n# Node 7: Select the new records from the collection (all of the records in the 0 table from Node 6)\nSelectFromCollection_node_7 = SelectFromCollection.apply(\n    dfc=CustomTransform_node_6,\n    key=list(CustomTransform_node_6.keys())[0],\n    transformation_ctx=\"SelectFromCollection_node_7\",\n)\n\n# Node 8: Append any new rows to the AWS Glue Data Catalog movies table in the transform-movies-db database\nAWSGlueDataCatalog_node_8 = glueContext.write_dynamic_frame.from_catalog(\n    frame=SelectFromCollection_node_7,\n    database=\"transform-movies-db\",\n    table_name=\"movies\",\n    transformation_ctx=\"AWSGlueDataCatalog_node_8\",\n)\n\njob.commit()\n"
}